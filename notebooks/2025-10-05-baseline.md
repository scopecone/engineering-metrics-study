# Engineering Metrics Baseline · 2025-10-05 Snapshot

This draft notebook captures the first pass over the expanded OSS cohort so we can line it up against the Engineering Metrics Simulator assumptions.

## Cohort Overview
- **Tracked repos:** 280 (after pruning eight zero-signal repos in the latest discovery batch; see “Holdout adjustments”).
- **Metrics rows:** 280 (filtered to the current sample; one row per repo).
- **Observation window:** 365-day pull (Actions where available, otherwise Deployments/Releases).
- **Data freshness:** Incremental collector last run `2025-10-05T08:22Z`.

## Holdout adjustments
| Removed slug | Reason |
| --- | --- |
| adamcohenhillel/ADeus | No merged PRs in 365-day window |
| CMU-Perceptual-Computing-Lab/openpose | Releases stale since 2020 |
| FiloSottile/mkcert | Releases stale since 2022 |
| garylab/MakeMoneyWithAI | No merged PRs in window |
| Genymobile/scrcpy | PRs merge into `dev`, not default branch |
| google-research/bert | Archived upstream |
| ksm26/Multi-AI-Agent-Systems-with-crewAI | No merged PRs in window |
| LinShunKang/MyPerf4J | No merged PRs in window |

These repos now live in `config/repos.holdout.json` and their cached payloads have been purged.

## Deployment Frequency by Ecosystem
| Language | Repos | Median DF | P75 DF | P85 DF | P95 DF | Median PR (h) | P75 PR (h) |
| --- | ---: | ---: | ---: | ---: | ---: | ---: | ---: |
| Go | 68 | **1.0** | 1.13 | 2.00 | 5.30 | 23.4 | 72.7 |
| TypeScript | 57 | **1.0** | 2.00 | 4.00 | 16.0 | **6.0** | 19.1 |
| Python | 46 | **1.0** | 2.75 | 5.00 | 28.4 | 14.2 | 22.6 |
| Java | 23 | **1.0** | 2.00 | 2.00 | 3.90 | 26.5 | 48.0 |
| C++ | 15 | **1.0** | 1.50 | 2.90 | 8.50 | 26.0 | 52.3 |

**Early read:** Deployment medians cluster around 1/week regardless of language, but the tail widens for TypeScript/Python cohorts. TypeScript teams pair that with notably faster PR cycle medians (~6 h) than Go (~23 h). Bootstrap 95% CIs for PR medians – TypeScript (4.2 h, 12.5 h) vs Go (17.5 h, 44.1 h) – show non-overlapping ranges, supporting a material gap.

## Scale Effects
Size tiers are based on merged PR counts over the window.

| Tier | Repos | Median DF | P75 DF | P85 DF | P95 DF | Median PR (h) | P75 PR (h) |
| --- | ---: | ---: | ---: | ---: | ---: | ---: | ---: |
| Small (<100 PRs) | 182 | 1.0 | 2.00 | 3.92 | 7.0 | 19.6 | 48.1 |
| Medium (100–499 PRs) | 77 | 1.0 | 2.00 | 2.60 | 5.60 | 18.9 | 30.6 |
| Large (≥500 PRs) | 21 | 1.0 | 5.00 | **19.0** | **225** | **10.1** | 16.5 |

**Outlier note:** The P95 spike for large cohorts is driven by ultra-high-frequency deployments at `getsentry/sentry` (≈320 prod deployments/week) and `PostHog/posthog` (≈225/week). Dropping those two outliers pulls the large-tier P95 down to ≈27.6 deployments/week; we’ll present both raw and trimmed tails so readers understand the automation extremes.

**Takeaway:** High-throughput teams sustain markedly shorter PR cycles (~10 h median) while the deployment tail widens dramatically. This validates the simulator’s assumption that automation enables faster merges, but we need to account for the heavy tail when presenting community baselines.

## MTTR / CFR Prototype (n = 14 repos, exploratory only)
Revert-driven heuristics over a 120-day window (see `output/metrics-mttr-cfr-extended.json`). Ten of the fourteen repos recorded at least one revert; the median MTTR across those revert-positive repos is **26.1 h**, and the median change-failure rate is **0.02** (reverts/deploys). Budibase surfaced the only incident-labelled issue so far (1 hit).

| Repo | Deployment Count | Reverts | Median Recovery (h) | CFR (reverts/deploys) |
| --- | ---: | ---: | ---: | ---: |
| getsentry/sentry | 16 394 | 108 | **2.7** | 0.66 % |
| growthbook/growthbook | 4 648 | 2 | 33.0 | 0.04 % |
| openstatusHQ/openstatus | 2 661 | 2 | 0.04 | 0.08 % |
| Budibase/budibase | 228 | 17 | 26.8 | 7.46 % |
| langfuse/langfuse | 223 | 10 | 33.1 | 4.48 % |
| ClickHouse/ClickHouse | 100 | 70 | 25.3 | 70.0 % |
| metabase/metabase | 117 | 30 | 152.1 | 25.6 % |
| vercel/next.js | 19 | 5 | 24.8 | 26.3 % |
| 18F/identity-idp | 108 | 4 | 130.1 | 3.7 % |
| TobikoData/sqlmesh | 217 | 1 | 0.0 | 0.46 % |

Repos such as Unleash, PostHog, chakra-ui, and AFFiNE had zero flagged reverts in the window; we keep them in the dataset but treat their MTTR/CFR as “not observed.”

**Caveats:**
- MTTR window currently uses 120 days (recent snapshot) while deployment/PR metrics cover 365 days. Align the windows or present separate “recent” charts before publication.
- Revert detection relies on `This reverts commit…` messages; silent rollbacks/feature flags escape the heuristic. For openstatusHQ the two reverts landed within minutes (0.8 min and 3.4 min), explaining the near-zero median.
- Incidents are still sparse (1 hit). Need manual label audit and possibly additional label synonyms before citing CFR/MTTR in the blog post.
- Coverage is wider but still limited (14/280 repos ≈ 5 %). Expand to ≥20–30 repos across ecosystems, and consider 365-day MTTR once rate-limit handling is improved.

## Open Questions / TODO
- [ ] Cross-check simulator priors (Wilkes, Rüegger) against the aggregate numbers above—load their baseline medians so the deltas are explicit. **Owner:** Carlo (target 2024-10-12).
- [ ] Expand MTTR sample to backend-heavy repos (e.g., `Kong/kong`, `temporalio/temporal`) and explore additional revert patterns (`git revert -m` merges).
- [ ] Add notebooks/plots for PR size vs cycle time; current snapshots don’t include PR diff statistics.
- [ ] Investigate anomalously slow-cycle repositories (`iina/iina`, `wallabag/wallabag`) once their PR activity ramps; flag if they remain outliers.
- [ ] Prepare blog-ready charts (language vs cycle time, size tier vs deployment tail) once storytelling angle is locked.
- [ ] Decide whether to combine multi-method deployment rows into a single per-repo aggregate or keep them separated but annotate analyses accordingly.
